{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd9e687-e84d-4b6d-bafe-ad14d2fdbe6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15 Mar 2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>Bargara Beach</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Brooklyn Sauer</td>\n",
       "      <td>F</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark</td>\n",
       "      <td>Yahoo News, 3/15/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04 Mar 2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Old Man's, Waikiki</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Matthew White</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark 8'</td>\n",
       "      <td>Surfer, 3/6/2024F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02 Mar-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Rainbows, Oahu</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>3' to 4' shark</td>\n",
       "      <td>Hawaii News Now, 3/4/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25 Feb-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Sandlnd Island, Jurian Bay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark</td>\n",
       "      <td>WA Today, 2/26/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14 Feb-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Vaitarna River, Palghar District</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>Vicky Suresh Govari</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>Bull shark, 7'</td>\n",
       "      <td>Times of India, 2/14/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6964</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6965</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6966</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6967</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6968</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6969 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date    Year        Type    Country              State  \\\n",
       "0     15 Mar 2024  2024.0  Unprovoked  AUSTRALIA         Queensland   \n",
       "1     04 Mar 2024  2024.0  Unprovoked        USA             Hawaii   \n",
       "2     02 Mar-2024  2024.0  Unprovoked        USA             Hawaii   \n",
       "3     25 Feb-2024  2024.0  Unprovoked  AUSTRALIA  Western Australia   \n",
       "4     14 Feb-2024  2024.0  Unprovoked      INDIA        Maharashtra   \n",
       "...           ...     ...         ...        ...                ...   \n",
       "6964          NaN     NaN         NaN        NaN                NaN   \n",
       "6965          NaN     NaN         NaN        NaN                NaN   \n",
       "6966          NaN     NaN         NaN        NaN                NaN   \n",
       "6967          NaN     NaN         NaN        NaN                NaN   \n",
       "6968          NaN     NaN         NaN        NaN                NaN   \n",
       "\n",
       "                              Location  Activity                 Name  Sex  \\\n",
       "0                        Bargara Beach  Swimming       Brooklyn Sauer    F   \n",
       "1                   Old Man's, Waikiki   Surfing        Matthew White    M   \n",
       "2                       Rainbows, Oahu  Swimming                  NaN    F   \n",
       "3           Sandlnd Island, Jurian Bay       NaN               female    F   \n",
       "4     Vaitarna River, Palghar District   Fishing  Vicky Suresh Govari    M   \n",
       "...                                ...       ...                  ...  ...   \n",
       "6964                               NaN       NaN                  NaN  NaN   \n",
       "6965                               NaN       NaN                  NaN  NaN   \n",
       "6966                               NaN       NaN                  NaN  NaN   \n",
       "6967                               NaN       NaN                  NaN  NaN   \n",
       "6968                               NaN       NaN                  NaN  NaN   \n",
       "\n",
       "      Age  ...        Species                      Source  pdf  \\\n",
       "0      13  ...     Tiger shark      Yahoo News, 3/15/2024  NaN   \n",
       "1     NaN  ...  Tiger shark 8'          Surfer, 3/6/2024F  NaN   \n",
       "2      11  ...  3' to 4' shark  Hawaii News Now, 3/4/2024  NaN   \n",
       "3      46  ...     Tiger shark        WA Today, 2/26/2024  NaN   \n",
       "4      32  ...  Bull shark, 7'  Times of India, 2/14/2024  NaN   \n",
       "...   ...  ...             ...                        ...  ...   \n",
       "6964  NaN  ...             NaN                        NaN  NaN   \n",
       "6965  NaN  ...             NaN                        NaN  NaN   \n",
       "6966  NaN  ...             NaN                        NaN  NaN   \n",
       "6967  NaN  ...             NaN                        NaN  NaN   \n",
       "6968  NaN  ...             NaN                        NaN  NaN   \n",
       "\n",
       "                                           href formula href Case Number  \\\n",
       "0                                                   NaN  NaN         NaN   \n",
       "1                                                   NaN  NaN         NaN   \n",
       "2                                                   NaN  NaN         NaN   \n",
       "3                                                   NaN  NaN         NaN   \n",
       "4                                                   NaN  NaN         NaN   \n",
       "...                                                 ...  ...         ...   \n",
       "6964  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN         NaN   \n",
       "6965  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN         NaN   \n",
       "6966  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN         NaN   \n",
       "6967  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN         NaN   \n",
       "6968  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN         NaN   \n",
       "\n",
       "     Case Number.1 original order Unnamed: 21 Unnamed: 22  \n",
       "0              NaN            NaN         NaN         NaN  \n",
       "1              NaN            NaN         NaN         NaN  \n",
       "2              NaN            NaN         NaN         NaN  \n",
       "3              NaN            NaN         NaN         NaN  \n",
       "4              NaN            NaN         NaN         NaN  \n",
       "...            ...            ...         ...         ...  \n",
       "6964           NaN            NaN         NaN         NaN  \n",
       "6965           NaN            NaN         NaN         NaN  \n",
       "6966           NaN            NaN         NaN         NaN  \n",
       "6967           NaN            NaN         NaN         NaN  \n",
       "6968           NaN            NaN         NaN         NaN  \n",
       "\n",
       "[6969 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(\"GSAF5.xls\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a652a3c8-b2a7-4653-9e7f-e7990afd9996",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique states in USA : ['Hawaii' 'Florida' 'California' 'South Carolina' 'North Carolina'\n",
      " 'New York' 'New Jersey' 'Samoa' 'Texas' 'Louisiana' 'Mississippi'\n",
      " 'Noirth Carolina' 'Georgia' 'Alabama' 'Maryland' 'Bahamas' 'Maui'\n",
      " 'Oregon' 'Franklin County, Florida' 'Virgin Islands' 'Maine' 'Delaware'\n",
      " 'Guam' 'Cayman Islands' 'Rhode Island' 'Massachusetts' 'Washington'\n",
      " 'Palmyra Atoll' 'Puerto Rico' 'Virginia' 'Us Virgin Islands' 'Kentucky'\n",
      " 'New Mexico' 'Johnston Atoll' 'Alaska' 'Missouri' 'Nan'\n",
      " 'North & South Carolina' 'Carolina Coast' 'Connecticut' 'Pennsylvania'\n",
      " 'Illinois' 'Wake Island' 'Midway Atoll' 'East Coast' 'Cuba']\n",
      "Unique states in USA : ['Hawaii' 'Florida' 'California' 'South Carolina' 'North Carolina'\n",
      " 'New York' 'New Jersey' 'Samoa' 'Texas' 'Louisiana' 'Mississippi'\n",
      " 'Noirth Carolina' 'Georgia' 'Alabama' 'Maryland' 'Bahamas' 'Maui'\n",
      " 'Oregon' 'Franklin County, Florida' 'Virgin Islands' 'Maine' 'Delaware'\n",
      " 'Guam' 'Cayman Islands' 'Rhode Island' 'Massachusetts' 'Washington'\n",
      " 'Palmyra Atoll' 'Puerto Rico' 'Virginia' 'Us Virgin Islands' 'Kentucky'\n",
      " 'New Mexico' 'Johnston Atoll' 'Alaska' 'Missouri' 'Nan'\n",
      " 'North & South Carolina' 'Carolina Coast' 'Connecticut' 'Pennsylvania'\n",
      " 'Illinois' 'Wake Island' 'Midway Atoll' 'East Coast' 'Cuba']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>...</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>usa_states</th>\n",
       "      <th>USA Coast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15 Mar 2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>BARGARA BEACH</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Brooklyn Sauer</td>\n",
       "      <td>F</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04 Mar 2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>OLD MAN'S, WAIKIKI</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Matthew White</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Islands</td>\n",
       "      <td>Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02 Mar-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>RAINBOWS, OAHU</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Islands</td>\n",
       "      <td>Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25 Feb-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>SANDLND ISLAND, JURIAN BAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14 Feb-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>VAITARNA RIVER, PALGHAR DISTRICT</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>Vicky Suresh Govari</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6964</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>Nan</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6965</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>Nan</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6966</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>Nan</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6967</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>Nan</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6968</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>Nan</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6969 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date    Year        Type    Country              State  \\\n",
       "0     15 Mar 2024  2024.0  Unprovoked  AUSTRALIA         Queensland   \n",
       "1     04 Mar 2024  2024.0  Unprovoked        USA             Hawaii   \n",
       "2     02 Mar-2024  2024.0  Unprovoked        USA             Hawaii   \n",
       "3     25 Feb-2024  2024.0  Unprovoked  AUSTRALIA  Western Australia   \n",
       "4     14 Feb-2024  2024.0  Unprovoked      INDIA        Maharashtra   \n",
       "...           ...     ...         ...        ...                ...   \n",
       "6964          NaN     NaN         NaN        NAN                Nan   \n",
       "6965          NaN     NaN         NaN        NAN                Nan   \n",
       "6966          NaN     NaN         NaN        NAN                Nan   \n",
       "6967          NaN     NaN         NaN        NAN                Nan   \n",
       "6968          NaN     NaN         NaN        NAN                Nan   \n",
       "\n",
       "                              Location  Activity                 Name  Sex  \\\n",
       "0                        BARGARA BEACH  Swimming       Brooklyn Sauer    F   \n",
       "1                   OLD MAN'S, WAIKIKI   Surfing        Matthew White    M   \n",
       "2                       RAINBOWS, OAHU  Swimming                  NaN    F   \n",
       "3           SANDLND ISLAND, JURIAN BAY       NaN               female    F   \n",
       "4     VAITARNA RIVER, PALGHAR DISTRICT   Fishing  Vicky Suresh Govari    M   \n",
       "...                                ...       ...                  ...  ...   \n",
       "6964                               NAN       NaN                  NaN  NaN   \n",
       "6965                               NAN       NaN                  NaN  NaN   \n",
       "6966                               NAN       NaN                  NaN  NaN   \n",
       "6967                               NAN       NaN                  NaN  NaN   \n",
       "6968                               NAN       NaN                  NaN  NaN   \n",
       "\n",
       "      Age  ...  pdf                                       href formula href  \\\n",
       "0      13  ...  NaN                                                NaN  NaN   \n",
       "1     NaN  ...  NaN                                                NaN  NaN   \n",
       "2      11  ...  NaN                                                NaN  NaN   \n",
       "3      46  ...  NaN                                                NaN  NaN   \n",
       "4      32  ...  NaN                                                NaN  NaN   \n",
       "...   ...  ...  ...                                                ...  ...   \n",
       "6964  NaN  ...  NaN  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN   \n",
       "6965  NaN  ...  NaN  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN   \n",
       "6966  NaN  ...  NaN  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN   \n",
       "6967  NaN  ...  NaN  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN   \n",
       "6968  NaN  ...  NaN  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN   \n",
       "\n",
       "     Case Number Case Number.1 original order Unnamed: 21 Unnamed: 22  \\\n",
       "0            NaN           NaN            NaN         NaN         NaN   \n",
       "1            NaN           NaN            NaN         NaN         NaN   \n",
       "2            NaN           NaN            NaN         NaN         NaN   \n",
       "3            NaN           NaN            NaN         NaN         NaN   \n",
       "4            NaN           NaN            NaN         NaN         NaN   \n",
       "...          ...           ...            ...         ...         ...   \n",
       "6964         NaN           NaN            NaN         NaN         NaN   \n",
       "6965         NaN           NaN            NaN         NaN         NaN   \n",
       "6966         NaN           NaN            NaN         NaN         NaN   \n",
       "6967         NaN           NaN            NaN         NaN         NaN   \n",
       "6968         NaN           NaN            NaN         NaN         NaN   \n",
       "\n",
       "     usa_states USA Coast  \n",
       "0                     NaN  \n",
       "1       Islands   Islands  \n",
       "2       Islands   Islands  \n",
       "3                     NaN  \n",
       "4                     NaN  \n",
       "...         ...       ...  \n",
       "6964                  NaN  \n",
       "6965                  NaN  \n",
       "6966                  NaN  \n",
       "6967                  NaN  \n",
       "6968                  NaN  \n",
       "\n",
       "[6969 rows x 25 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Find unique val. for USA states\n",
    "tar_country = 'USA'\n",
    "unique_states = df[df['Country'] == tar_country]['State'].unique()\n",
    "\n",
    "print(\"Unique states in\", tar_country, \":\", unique_states)\n",
    "\n",
    "# for usa, new column with west coast, east coast, islands, other\n",
    "unique_states = ['HAWAII', 'FLORIDA', 'CALIFORNIA', 'SOUTH CAROLINA', 'NORTH CAROLINA',\n",
    "                 'NEW YORK', 'NEW JERSEY', 'SAMOA', 'TEXAS', 'LOUISIANA', 'MISSISSIPPI',\n",
    "                 'NOIRTH CAROLINA', 'GEORGIA', 'ALABAMA', 'MARYLAND', 'BAHAMAS', 'MAUI',\n",
    "                 'OREGON', 'FRANKLIN COUNTY, FLORIDA', 'VIRGIN ISLANDS', 'MAINE', 'DELAWARE',\n",
    "                 'GUAM', 'CAYMAN ISLANDS', 'RHODE ISLAND', 'MASSACHUSETTS', 'WASHINGTON',\n",
    "                 'PALMYRA ATOLL', 'PUERTO RICO', 'VIRGINIA', 'US VIRGIN ISLANDS', 'KENTUCKY',\n",
    "                 'NEW MEXICO', 'JOHNSTON ATOLL', 'ALASKA', 'MISSOURI', 'NAN',\n",
    "                 'NORTH & SOUTH CAROLINA', 'CAROLINA COAST', 'CONNECTICUT', 'PENNSYLVANIA',\n",
    "                 'ILLINOIS', 'WAKE ISLAND', 'MIDWAY ATOLL', 'EAST COAST', 'CUBA']\n",
    "\n",
    "tar_country = 'USA'\n",
    "\n",
    "unique_states = df[df['Country'] == tar_country]['State'].unique()\n",
    "print(\"Unique states in\", tar_country, \":\", unique_states)\n",
    "\n",
    "state_category_mapping = {\n",
    "    'West Coast': ['CALIFORNIA', 'OREGON', 'WASHINGTON'],\n",
    "    'East Coast': ['FLORIDA', 'SOUTH CAROLINA', 'NORTH CAROLINA', 'NEW YORK', 'NEW JERSEY', 'NOIRTH CAROLINA', 'GEORGIA', 'ALABAMA', 'MARYLAND', 'FRANKLIN COUNTY, FLORIDA', 'MAINE', 'DELAWARE', 'RHODE ISLAND', 'MASSACHUSETTS', 'CONNECTICUT', 'PENNSYLVANIA'],\n",
    "    'Islands': ['HAWAII', 'SAMOA', 'BAHAMAS', 'MAUI', 'VIRGIN ISLANDS', 'GUAM', 'CAYMAN ISLANDS', 'PALMYRA ATOLL', 'PUERTO RICO', 'US VIRGIN ISLANDS', 'JOHNSTON ATOLL', 'WAKE ISLAND', 'MIDWAY ATOLL', 'CUBA']}\n",
    "\n",
    "# Define a function to categorize the states\n",
    "def categorize_state(state):\n",
    "    for category, states in state_category_mapping.items():\n",
    "        if state.upper() in states:\n",
    "            return category\n",
    "    return 'Other'\n",
    "\n",
    "df['USA Coast'] = df.apply(lambda row: categorize_state(row['State']) if row['Country'] == 'USA' else np.nan, axis=1)\n",
    "\n",
    "df['State'] = df['State'].str.title()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bdc238-42fd-4ba2-9bd1-45f88ce00a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d98ba924-f2a8-43df-960b-fa65d2b24902",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique states in AUSTRALIA : ['QUEENSLAND' 'WESTERN AUSTRALIA' 'NEW  SOUTH WALES' 'SOUTH AUSTRALIA'\n",
      " 'NEW SOUTH WALES' 'WESTERM AUSTRALIA' 'NEW SOUTH ALES'\n",
      " 'WESTERN  AUSTRALIA' 'VICTORIA' 'NAN' 'TASMANIA' 'NORTHERN TERRITORY'\n",
      " 'TORRES STRAIT' 'TERRITORY OF COCOS (KEELING) ISLANDS' 'NORFOLK ISLAND']\n"
     ]
    }
   ],
   "source": [
    "tar_country = 'AUSTRALIA'\n",
    "\n",
    "# Filter the DataFrame based on the condition in the 'country' column and get unique states\n",
    "unique_states = df[df['Country'] == tar_country]['State'].unique()\n",
    "\n",
    "print(\"Unique states in\", tar_country, \":\", unique_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef7c24-3bb1-413c-9a25-ec88cda9f6c2",
   "metadata": {},
   "source": [
    "in gral: look at deleting all the duplicate rows, formating all columns heads, \n",
    "# Remove duplicates and reset the index\n",
    "df_without_duplicates = df.copy()\n",
    "df_without_duplicates = df.drop_duplicates(subset=['Sex', 'Age'])\n",
    "df_without_duplicates.tail() # look at the gaps in the index\n",
    "\n",
    "1. quick look at empty countries, and deleting all countries except austrailia and usa\n",
    "1. make them all capital\n",
    "2 null values \n",
    "check\n",
    "df.isna().any()\n",
    "count\n",
    "df.isna().sum()\n",
    "duplicates - no need for these 3 columns\n",
    "strings\n",
    "formating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6c3764e5-39ad-42e8-a826-177685165e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location\n",
       "Thursday Island                         9\n",
       "Havana Harbor                           9\n",
       "North Beach, Durban                     9\n",
       "Nahoon, East London                     9\n",
       "Near Thursday Island                    9\n",
       "Brisbane River                          9\n",
       "Daytona Beach Shores, Volusia County    8\n",
       "Port Said                               8\n",
       "Moreton Bay                             8\n",
       "Riviera Beach, Palm Beach County        8\n",
       "Quy Nhon                                8\n",
       "Folly Beach, Charleston County          8\n",
       "Oreti Beach                             8\n",
       "Country Club Beach, Durban              8\n",
       "Newcastle                               8\n",
       "Amanzimtoti                             8\n",
       "Sanibel Island, Lee County              8\n",
       "False Bay                               8\n",
       "Marathon, Monroe County                 7\n",
       "Key West, Monroe County                 7\n",
       "Gulf Shores, Baldwin County             7\n",
       "Plettenberg Bay                         7\n",
       "Fort Lauderdale, Broward County         7\n",
       "Charleston                              7\n",
       "Pensacola Bay, Escambia County          7\n",
       "Port Alfred                             7\n",
       "Huntington Beach, Orange County         7\n",
       "Ross River, Townsville                  7\n",
       "Coogee                                  7\n",
       "Bunbury                                 7\n",
       "Bondi                                   7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location'].value_counts()[29:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b6b9d7a-9ee2-451d-b919-0de030d01c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df['Country'] = df['Country'].astype(str)\n",
    "df['Location'] = df['Location'].astype(str)\n",
    "df['State'] = df['State'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "72a55493-43f2-4d43-96cf-d994caddc2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df['Country'].dtype)\n",
    "print(df['Location'].dtype)\n",
    "print(df['State'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1ab71a96-7d51-4887-8dda-17ca0a04f28e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Date, Year, Type, Country, State, Location, Activity, Name, Sex, Age, Injury, Unnamed: 11, Time, Species , Source, pdf, href formula, href, Case Number, Case Number.1, original order, Unnamed: 21, Unnamed: 22]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 23 columns]\n",
      "Date                25\n",
      "Year                27\n",
      "Type                43\n",
      "Country              0\n",
      "State                0\n",
      "Location             0\n",
      "Activity           611\n",
      "Name               245\n",
      "Sex                604\n",
      "Age               3019\n",
      "Injury              60\n",
      "Unnamed: 11        587\n",
      "Time              3551\n",
      "Species           3157\n",
      "Source              44\n",
      "pdf                170\n",
      "href formula       150\n",
      "href               173\n",
      "Case Number        171\n",
      "Case Number.1      172\n",
      "original order     170\n",
      "Unnamed: 21       6968\n",
      "Unnamed: 22       6967\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Rename column names:\n",
    "\n",
    "columns_to_check = ['Country', 'State', 'Location']\n",
    "\n",
    "#Check for datatypes\n",
    "column_types = df[['Country', 'State', 'Location']].dtypes\n",
    "\n",
    "# Filter the DataFrame to show only rows where any of the specified columns have missing values\n",
    "df['Country'].isna().sum()\n",
    "df['State'].isna().sum()\n",
    "df['Location'].isna().sum()\n",
    "missing_values_df = df[df[columns_to_check].isna().all(axis=1)]\n",
    "\n",
    "# Display the rows with missing values in any of the specified columns\n",
    "print(missing_values_df)\n",
    "\n",
    "#deleted all rows where both country state and location where empty - first delete empties for whole thing\n",
    "df_cleaned_nulls_csl= df.dropna(subset=columns_to_check, how='all')\n",
    "#double check result\n",
    "missing_values = df_cleaned_nulls_csl.isna().sum()\n",
    "print(missing_values) #for countries just 21 empty countries after deleting, should we fill up the info having the state/location?\n",
    "\n",
    "# Check for duplicates: no need for these columns\n",
    "\n",
    "#All countries in uppercase:\n",
    "df['Country'] = df['Country'].str.upper()\n",
    "#Stateas and Location in propercase:\n",
    "df['Location'] = df['Location'].str.upper()\n",
    "df['State'] = df['State'].str.upper()                                   \n",
    "                                        \n",
    "# Remove Whitespaces\n",
    "df['Country'] = df['Country'].str.strip()\n",
    "df['Location'] = df['Location'].str.strip()\n",
    "df['State'] = df['State'].str.strip()\n",
    "\n",
    "#Delete rows for other countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9ec0bdee-9c1b-4dee-b828-efc50e94cb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4693ad85-a062-4f72-b06b-3f148dd80bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in State\n",
      "['AUSTRALIA' 'USA' 'INDIA' 'TRINIDAD' 'BAHAMAS' 'SOUTH AFRICA' 'MEXICO'\n",
      " 'NEW ZEALAND' 'EGYPT' 'Mexico' 'BELIZE' 'PHILIPPINES' 'Coral Sea' 'SPAIN'\n",
      " 'PORTUGAL' 'SAMOA' 'COLOMBIA' 'ECUADOR' 'FRENCH POLYNESIA'\n",
      " 'NEW CALEDONIA' 'TURKS and CaICOS' 'CUBA' 'BRAZIL' 'SEYCHELLES'\n",
      " 'ARGENTINA' 'FIJI' 'MeXICO' 'Maldives' 'South Africa' 'ENGLAND' 'JAPAN'\n",
      " 'INDONESIA' 'JAMAICA' 'MALDIVES' 'THAILAND' 'COLUMBIA' 'COSTA RICA'\n",
      " 'New Zealand' 'British Overseas Territory' 'CANADA' 'JORDAN'\n",
      " 'ST KITTS / NEVIS' 'ST MARTIN' 'PAPUA NEW GUINEA' 'REUNION ISLAND'\n",
      " 'ISRAEL' 'CHINA' 'IRELAND' 'ITALY' 'MALAYSIA' 'LIBYA' nan 'MAURITIUS'\n",
      " 'SOLOMON ISLANDS' 'ST HELENA, British overseas territory' 'COMOROS'\n",
      " 'REUNION' 'UNITED KINGDOM' 'UNITED ARAB EMIRATES' 'CAPE VERDE' 'Fiji'\n",
      " 'DOMINICAN REPUBLIC' 'CAYMAN ISLANDS' 'ARUBA' 'MOZAMBIQUE' 'PUERTO RICO'\n",
      " 'ATLANTIC OCEAN' 'GREECE' 'ST. MARTIN' 'FRANCE' 'TRINIDAD & TOBAGO'\n",
      " 'KIRIBATI' 'DIEGO GARCIA' 'TAIWAN' 'PALESTINIAN TERRITORIES' 'GUAM'\n",
      " 'NIGERIA' 'TONGA' 'SCOTLAND' 'CROATIA' 'SAUDI ARABIA' 'CHILE' 'ANTIGUA'\n",
      " 'KENYA' 'RUSSIA' 'TURKS & CAICOS' 'UNITED ARAB EMIRATES (UAE)' 'AZORES'\n",
      " 'SOUTH KOREA' 'MALTA' 'VIETNAM' 'MADAGASCAR' 'PANAMA' 'SOMALIA' 'NEVIS'\n",
      " 'BRITISH VIRGIN ISLANDS' 'NORWAY' 'SENEGAL' 'YEMEN' 'GULF OF ADEN'\n",
      " 'Sierra Leone' 'ST. MAARTIN' 'GRAND CAYMAN' 'Seychelles' 'LIBERIA'\n",
      " 'VANUATU' 'MEXICO ' 'HONDURAS' 'VENEZUELA' 'SRI LANKA' ' TONGA' 'URUGUAY'\n",
      " 'MICRONESIA' 'CARIBBEAN SEA' 'OKINAWA' 'TANZANIA' 'MARSHALL ISLANDS'\n",
      " 'EGYPT / ISRAEL' 'NORTHERN ARABIAN SEA' 'HONG KONG' 'EL SALVADOR'\n",
      " 'ANGOLA' 'BERMUDA' 'MONTENEGRO' 'IRAN' 'TUNISIA' 'NAMIBIA'\n",
      " 'NORTH ATLANTIC OCEAN' 'SOUTH CHINA SEA' 'BANGLADESH' 'PALAU'\n",
      " 'WESTERN SAMOA' 'PACIFIC OCEAN ' 'BRITISH ISLES' 'GRENADA' 'IRAQ'\n",
      " 'TURKEY' 'SINGAPORE' 'NEW BRITAIN' 'SUDAN' 'JOHNSTON ISLAND'\n",
      " 'SOUTH PACIFIC OCEAN' 'NEW GUINEA' 'RED SEA' 'NORTH PACIFIC OCEAN'\n",
      " 'FEDERATED STATES OF MICRONESIA' 'MID ATLANTIC OCEAN' 'ADMIRALTY ISLANDS'\n",
      " 'BRITISH WEST INDIES' 'SOUTH ATLANTIC OCEAN' 'PERSIAN GULF'\n",
      " 'RED SEA / INDIAN OCEAN' 'PACIFIC OCEAN' 'NORTH SEA' 'NICARAGUA '\n",
      " 'MALDIVE ISLANDS' 'AMERICAN SAMOA' 'ANDAMAN / NICOBAR ISLANDAS' 'GABON'\n",
      " 'MAYOTTE' 'NORTH ATLANTIC OCEAN ' 'THE BALKANS' 'SUDAN?' 'MARTINIQUE'\n",
      " 'INDIAN OCEAN' 'GUATEMALA' 'NETHERLANDS ANTILLES'\n",
      " 'NORTHERN MARIANA ISLANDS' 'IRAN / IRAQ' 'JAVA' 'SIERRA LEONE'\n",
      " ' PHILIPPINES' 'NICARAGUA' 'CENTRAL PACIFIC' 'SOLOMON ISLANDS / VANUATU'\n",
      " 'SOUTHWEST PACIFIC OCEAN' 'BAY OF BENGAL' 'MID-PACIFC OCEAN' 'SLOVENIA'\n",
      " 'CURACAO' 'ICELAND' 'ITALY / CROATIA' 'BARBADOS' 'MONACO' 'GUYANA'\n",
      " 'HAITI' 'SAN DOMINGO' 'KUWAIT' 'YEMEN ' 'FALKLAND ISLANDS' 'CRETE'\n",
      " 'CYPRUS' 'EGYPT ' 'WEST INDIES' 'BURMA' 'LEBANON' 'PARAGUAY'\n",
      " 'BRITISH NEW GUINEA' 'CEYLON' 'OCEAN' 'GEORGIA' 'SYRIA' 'TUVALU'\n",
      " 'INDIAN OCEAN?' 'GUINEA' 'ANDAMAN ISLANDS' 'EQUATORIAL GUINEA / CAMEROON'\n",
      " 'COOK ISLANDS' 'TOBAGO' 'PERU' 'AFRICA' 'ALGERIA' 'Coast of AFRICA'\n",
      " 'TASMAN SEA' 'GHANA' 'GREENLAND' 'MEDITERRANEAN SEA' 'SWEDEN' 'ROATAN'\n",
      " 'Between PORTUGAL & INDIA' 'DJIBOUTI' 'BAHREIN' 'KOREA' 'RED SEA?'\n",
      " 'ASIA?' 'CEYLON (SRI LANKA)']\n",
      "225\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Unique values in State')\n",
    "print(df['Country'].unique())\n",
    "print(df['Country'].nunique())\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8edf9-c793-40ad-b0b0-2acce8365bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def initial_categorize_activity(activity):\n",
    "    activity_str = str(activity)  # Ensure the activity is treated as a string\n",
    "    activity_lower = activity_str.lower()\n",
    "    if 'swim' in activity_lower:\n",
    "        return 'swimming_1'\n",
    "    elif 'fish' in activity_lower:\n",
    "        return 'fishing_1'\n",
    "    elif 'surf' in activity_lower or 'board' in activity_lower:\n",
    "        return 'water_sports_1'\n",
    "    else:\n",
    "        return 'other_1'\n",
    "\n",
    "# Convert the 'activities' column to strings\n",
    "df_florida['Activity'] = df_florida['Activity'].astype(str)\n",
    "\n",
    "# Apply the initial categorization function to the 'activities' column\n",
    "df_florida['initial_category'] = df_florida['Activity'].apply(initial_categorize_activity)\n",
    "\n",
    "# Create a DataFrame for manual categorization\n",
    "df_florida = df_florida[df_florida['initial_category'] == 'other_1'].copy()\n",
    "\n",
    "# Manually categorize each activity in manual_df\n",
    "manual_categorization = {\n",
    "    'Sitting': 'other',\n",
    "    'Wading': 'swimming',\n",
    "    'Lobstering': 'fishing',\n",
    "    'Scalloping': 'fishing',\n",
    "    'Jumped into water': 'swimming',\n",
    "    'Standing': 'other',\n",
    "    'Playing': 'other',\n",
    "    'Walking': 'other',\n",
    "    'Feeding sharks': 'other',\n",
    "    'Photo shoot': 'other',\n",
    "    'Teasing a shark': 'other',\n",
    "    'SUP': 'water sports',\n",
    "    'Photographing fish': 'other',\n",
    "    'Attempting to rescue a shark': 'other',\n",
    "    'Photographing the shark': 'other',\n",
    "    'Casting a net': 'fishing',\n",
    "    'Playing in the surf': 'water sports',\n",
    "    'Free diving ': 'water sports',\n",
    "    'Jet skiing': 'water sports',\n",
    "    'Scuba diving': 'water sports',\n",
    "    'Measuring sharks': 'other',\n",
    "    'Crawling': 'other',\n",
    "    'Walking out of the water after surfing': 'water sports',\n",
    "    'Wading?': 'swimming',\n",
    "    'Jumping': 'other',\n",
    "    'Floating near boat & observing bioluminesce': 'other',\n",
    "    'Jumped into the water': 'swimming',\n",
    "    'Removing hook from shark': 'fishing',\n",
    "    'Playing on a sandbar': 'other',\n",
    "    'Shrimping': 'fishing',\n",
    "    'Playing soccer in the water': 'other',\n",
    "    'Diving / Kissing the shark': 'water sports',\n",
    "    'Treading water/ Surfing': 'water sports',\n",
    "    'Standing / Surfing': 'water sports',\n",
    "    'Crouching in 2\\' of water': 'swimming',\n",
    "    'In water with diving seabirds': 'water sports',\n",
    "    'Walking, carrying surfboard & stepped on shark': 'water sports',\n",
    "    'Petting captive sharks': 'other',\n",
    "    'Floating on a raft': 'water sports',\n",
    "    'Playing in the surf with his 2 dogs': 'water sports',\n",
    "    'Wreck / Technical diving': 'water sports',\n",
    "    'Walking in shallows': 'swimming',\n",
    "    'Attempting to illegally enter the USA': 'other',\n",
    "    'Sailing': 'water sports'\n",
    "}\n",
    "\n",
    "df_florida['manual_category'] = df_florida['Activity'].map(manual_categorization)\n",
    "\n",
    "# Combine initial and manual categorization\n",
    "df_florida['Activity Category'] = df_florida['initial_category']\n",
    "df_florida.loc[df_florida['initial_category'] == 'other_1', 'Activity Category'] = df_florida['manual_category'].values\n",
    "\n",
    "# Replace final category names\n",
    "df_florida['Activity Category'] = df_florida['Activity Category'].replace({\n",
    "    'swimming_1': 'swimming',\n",
    "    'fishing_1': 'fishing',\n",
    "    'water_sports_1': 'water sports'\n",
    "})\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)\n",
    "df_florida.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ca346-7d5b-4541-9a0d-595a32a0efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################7\n",
    "# ACTIVITY CATEGORY (NEW COLUMN)\n",
    "############################\n",
    "\n",
    "# WE´LL NEED TO CHANGE INDEX\n",
    "# Function to categorize activities\n",
    "def categorize_activity(activity):\n",
    "    activity_str = str(activity)  # Ensure the activity is treated as a string\n",
    "    activity_lower = activity_str.lower()  # Ensure all lowercase\n",
    "    if 'swim' in activity_lower:\n",
    "        return 'swimming'\n",
    "    elif 'fish' in activity_lower:\n",
    "        return 'fishing'\n",
    "    elif 'surf' in activity_lower or 'board' in activity_lower or 'div':\n",
    "        return 'water sports'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "# Apply the categorization function to the 'activities' column and create the 'activity_category' column\n",
    "df_florida['activity_category'] = df_florida['Activity'].apply(categorize_activity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
